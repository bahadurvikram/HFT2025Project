theme = myTheme)
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(3, 2), mar = c(4, 4, 2, 1))  # This sets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
add_TA(cumsum(daily.pnls.xts$pnl.net[!is.na(daily.pnls.xts$pnl.net)]),
col = "red",
on = 1)
source("/Volumes/Macintosh HD 2/Users/vikrambaha/QF-YEAR-2/HFT/project/main_group1.R", echo=TRUE)
View(max_sr)
View(test1)
View(data2)
rm(list = ls())
source("https://raw.githubusercontent.com/ptwojcik/HFD/master/functions_plotHeatmap.R")
source("functions/load_and_pre_process.R")
source("functions/define_entry_exit.R")
source("functions/execute_strategies.R")
source("functions/define_daily_filters.R")
source("functions/execute_one_at_a_time.R")
data2 <- load_and_pre_process("data/data1_2023_Q4.RData")
daily.calc <- define_daily_filters(data2)
daily.calc <- daily.calc[-nrow(daily.calc)]
#fid av.ratio, sds.ratio and respective spread for both prices and returns
data2 <- define_entry_exit(data2)
data2 <- data2[-nrow(data2)]
weeks_points <- endpoints(data2, "weeks")
rm(max_sr)
max_sr <- period.apply(data2, INDEX = weeks_points,
FUN = execute_strategies)
excl_first_week_index <- index(data2[week(index(data2))!=40]) # need to check for other quarters
week(index(data2)
)
#index(max_sr) <- index(org_sr) + 3 * 16.5 * 60 * 60
index(max_sr) <- index(max_sr) + (2 * 24 * 60 * 60 + .75*24*60*60 - 60*30)
max_sr <- max_sr[-nrow(max_sr)]
#daily_dates <- seq(from = first_date, to = last_date, by = "min")
test1 <- merge(max_sr,excl_first_week_index)
# Filled the missing with last non-missing values
test1$spread.name <- na.locf(test1$spread.name)
test1$m <- na.locf(test1$m)
test1$volat.sd <- na.locf(test1$volat.sd)
test1$net.SR <- na.locf(test1$net.SR)
data2 <- merge(data2, test1)
day_points <- endpoints(data2, "days")
rm(daily.pnls.xts)
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
source("functions/execute_one_at_a_time.R")
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
data[temp,]
data[temp,][1]
index(data[temp,])
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
source("functions/execute_one_at_a_time.R")
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
View(data2)
rm(list = ls())
source("https://raw.githubusercontent.com/ptwojcik/HFD/master/functions_plotHeatmap.R")
source("functions/load_and_pre_process.R")
source("functions/define_entry_exit.R")
source("functions/execute_strategies.R")
source("functions/define_daily_filters.R")
source("functions/execute_one_at_a_time.R")
data2 <- load_and_pre_process("data/data1_2023_Q4.RData")
View(data2)
source("functions/execute_one_at_a_time.R")
View(data2)
rm(daily.pnls.xts)
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
rm(list = ls())
source("https://raw.githubusercontent.com/ptwojcik/HFD/master/functions_plotHeatmap.R")
source("functions/load_and_pre_process.R")
source("functions/define_entry_exit.R")
source("functions/execute_strategies.R")
source("functions/define_daily_filters.R")
source("functions/execute_one_at_a_time.R")
data2 <- load_and_pre_process("data/data1_2023_Q4.RData")
daily.calc <- define_daily_filters(data2)
daily.calc <- daily.calc[-nrow(daily.calc)]
#fid av.ratio, sds.ratio and respective spread for both prices and returns
data2 <- define_entry_exit(data2)
data2 <- data2[-nrow(data2)]
weeks_points <- endpoints(data2, "weeks")
rm(max_sr)
max_sr <- period.apply(data2, INDEX = weeks_points,
FUN = execute_strategies)
excl_first_week_index <- index(data2[week(index(data2))!=40]) # need to check for other quarters
#index(max_sr) <- index(org_sr) + 3 * 16.5 * 60 * 60
index(max_sr) <- index(max_sr) + (2 * 24 * 60 * 60 + .75*24*60*60 - 60*30)
max_sr <- max_sr[-nrow(max_sr)]
#daily_dates <- seq(from = first_date, to = last_date, by = "min")
test1 <- merge(max_sr,excl_first_week_index)
# Filled the missing with last non-missing values
test1$spread.name <- na.locf(test1$spread.name)
test1$m <- na.locf(test1$m)
test1$volat.sd <- na.locf(test1$volat.sd)
test1$net.SR <- na.locf(test1$net.SR)
data2 <- merge(data2, test1)
day_points <- endpoints(data2, "days")
rm(daily.pnls.xts)
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
View(daily.pnls.xts)
rm(daily.pnls.xts)
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
nrow(data[temp,]
)
data
nrow(data)
rm(daily.pnls.xts)
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
View(daily.pnls.xts)
source("functions/execute_one_at_a_time.R")
rm(daily.pnls.xts)
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
View(daily.pnls.xts)
# we need to remove hours from this index too
index(daily.pnls.xts) <- as_date(index(daily.pnls.xts))
index(daily.calc) <- as_date(index(daily.calc))
# then we can apply merging
daily.pnls.xts <- merge(daily.pnls.xts, daily.calc)
av.daily.ntrans <- mean(daily.pnls.xts$ntrans, na.rm = TRUE)
ann_gross_sr <- mySR(daily.pnls.xts$pnl.gross[-5],
scale = 252)
ann_net_sr <- mySR(daily.pnls.xts$pnl.net[-5],
scale = 252)
myCalmarRatio <- function(x, # x = series of returns
# scale parameter = Nt
scale) {
scale * mean(coredata(x), na.rm = TRUE) /
maxdrawdown(cumsum(x))$maxdrawdown
}
# sample column
ann_gross_cr <- myCalmarRatio(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)],
scale = 252)
ann_net_cr <-myCalmarRatio(daily.pnls.xts$pnl.net[!is.na(daily.pnls.xts$pnl.net)],
scale = 252)
gross_cumPnL <- tail(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),1)
net_cumPnL <- tail(cumsum(daily.pnls.xts$pnl.net[!is.na(daily.pnls.xts$pnl.net)]),1)
# lets see it on the plot
myTheme <- chart_theme()
myTheme$col$line.col <- "darkblue"
par(mfrow = c(3, 2), mar = c(4, 4, 2, 1))  # This sets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(3, 2), mar = c(4, 4, 2, 1))  # This sets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(3, 2), mar = c(4, 4, 2, 1))  # This sets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
add_TA(cumsum(daily.pnls.xts$pnl.net[!is.na(daily.pnls.xts$pnl.net)]),
col = "red",
on = 1)
View(gross_cumPnL)
av.daily.ntrans
ann_gross_sr
ann_net_sr
ann_gross_cr
ann_net_cr
gross_cumPnL
net_cumPnL
source("/Volumes/Macintosh HD 2/Users/vikrambaha/QF-YEAR-2/HFT/project/main_group1.R", echo=TRUE)
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(3, 2), mar = c(4, 4, 2, 1))  # This sets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
add_TA(cumsum(daily.pnls.xts$pnl.net[!is.na(daily.pnls.xts$pnl.net)]),
col = "red",
on = 1)
av.daily.ntrans
ann_gross_sr
ann_net_sr
ann_gross_cr
ann_net_cr
gross_cumPnL
net_cumPnL
rm(list = ls())
source("/Volumes/Macintosh HD 2/Users/vikrambaha/QF-YEAR-2/HFT/project/main_group1.R", echo=TRUE)
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(3, 2), mar = c(4, 4, 2, 1))  # This sets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
par(mfrow = c(1, 1))  # This resets the margins
chart_Series(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),
theme = myTheme)
add_TA(cumsum(daily.pnls.xts$pnl.net[!is.na(daily.pnls.xts$pnl.net)]),
col = "red",
on = 1)
av.daily.ntrans
ann_gross_sr
ann_net_sr
ann_gross_cr
ann_net_cr
gross_cumPnL
net_cumPnL
?runsma
?runsd
?caTools
## Get present location
LOC_CODE = dirname(rstudioapi::getSourceEditorContext()$path)
print(LOC_CODE)
## Set it as current working directory
setwd(LOC_CODE)
rm(list = ls())
source("https://raw.githubusercontent.com/ptwojcik/HFD/master/functions_plotHeatmap.R")
source("functions/load_and_pre_process.R")
source("functions/define_entry_exit.R")
source("functions/execute_strategies.R")
source("functions/define_daily_filters.R")
source("functions/execute_one_at_a_time.R")
source("functions/positionVB_double_new.R")
data2 <- load_and_pre_process("data/data1_2024_Q2.RData")
View(data2)
# lets create a pos_flat vector and fill it with 0s
pos_flat <- xts(rep(0, nrow(data)), index(data))
rm(data2)
data <- load_and_pre_process("data/data1_2024_Q2.RData")
# lets create a pos_flat vector and fill it with 0s
pos_flat <- xts(rep(0, nrow(data)), index(data))
pos_flat["T00:00/T09:55"] <- 1
pos_flat["T15:39/T23:59"] <- 1
volat.sd = 120
mv.mean = 60
m_ = 3
for(volat.sd in c(60, 90, 120, 150, 180)) { # different volatility memories
for (mv.mean in c(c(60, 90, 120, 150, 180))) {
for(m_ in c( 2, 2.5, 3, 3.5)) { # different multipliers
message(paste0("volat.sd = ", volat.sd,", m_ = ", m_))
# calculating elements of the strategy
signal <- data$NQ.close
sma <- runmean(data, k = mv.mean, endrule = "NA", align = "right")
sda <- runsd(signal, volat.sd, endrule = "NA", align = "right")
upper_entry <- sma + (m_+2) * sda
lower_entry <- sma - (m_+2) * sda
upper_exit <- sma + m_ * sda
upper_exit <- sma - m_ * sda
# position for mean-reverting strategy
pos.mr <- positionVB_double_new(signal, lower_entry, lower_exit,
upper_entry, upper_exit,
pos_flat = pos_flat,
strategy = "mr" # important !!!
)
# number of transactions
ntrans <- abs(diff.xts(pos.mr))
# gross pnl
gross.pnl <- (pos.mr) *
(diff.xts(NQ_price) * 20 # point value for NQ
- coredata(data$av.ratio) * diff.xts(SP_price) * 50 ) # point value for SP
# pnl after  costs
# costs = 12$ for AAPL and 4$ for NASDAQ = (4+m*12) in total
# there is NO minus "-" in the costs - they are always positive !!!
net.pnl <- gross.pnl - ntrans * (12 + coredata(data$av.ratio) * 12)
# aggregate to daily
ends_ <- endpoints(data, "days")
pnl.gross.d <- period.apply(gross.pnl, INDEX = ends_,
FUN = function(x) sum(x, na.rm = TRUE))
pnl.net.d <- period.apply(net.pnl, INDEX = ends_,
FUN = function(x) sum(x, na.rm = TRUE))
ntrans.d <- period.apply(ntrans, INDEX = ends_,
FUN = function(x) sum(x, na.rm = TRUE))
# calculate summary measures
gross.SR <- mySR(pnl.gross.d, scale = 252)
net.SR <- mySR(pnl.net.d, scale = 252)
gross.PnL <- sum(pnl.gross.d, na.rm = TRUE)
net.PnL <- sum(pnl.net.d, na.rm = TRUE)
av.daily.ntrans <- mean(ntrans.d, na.rm = TRUE)
av.daily.ntrans2 <- mean(ntrans2.d, na.rm = TRUE)
# summary of a particular strategy
summary_ <- data.frame(
volat.sd = volat.sd,
m = m_,
period = "2022-01-03 - 2022-03",
gross.SR,
net.SR,
gross.PnL,
net.PnL,
av.daily.ntrans,
stringsAsFactors = FALSE)
# putting all summaries together
if(!exists("summary.pair.trading")) summary.pair.trading <- rbind(summary_) else
summary.pair.trading <- rbind(summary.pair.trading, summary_)
# deleting working files not needed any more
rm(gross.SR, net.SR,
gross.PnL, net.PnL,
av.daily.ntrans,
pnl.gross.d, pnl.net.d,
ntrans.d,
pnl.gross, pnl.net,
ntrans,
pos.mr, ends_, summary_,
signal, lower_entry, lower_exit, upper_entry, upper_exit)
} # end of loop for m_
} # end of loop for mean
} # end of loop for volatility
View(data)
-1.978189-1.530431+7.09879+27.48605+14.41213+1.070789-1.552525
-14452.74-9247.564+14865.49+40750.74+22088.17+3430.214-4716.803
52717.51/1000
log(52.71751)
3.964948 * 45.00661
7349.15+12861.50+10190.79+6517.58+4254.25+7781.34-7023.33
week(index(data2))
week(index(data))
week(index(data))[1]
class(week(index(data))[1])
?cor
?urca.kpss
?ur.kpss
## Get present location
LOC_CODE = dirname(rstudioapi::getSourceEditorContext()$path)
print(LOC_CODE)
## Set it as current working directory
setwd(LOC_CODE)
rm(list = ls())
###############################################
# Install dependent source code
###############################################
source("https://raw.githubusercontent.com/ptwojcik/HFD/master/functions_plotHeatmap.R")
source("functions/load_and_pre_process.R")
source("functions/define_entry_exit.R")
source("functions/execute_strategies.R")
source("functions/define_daily_filters.R")
source("functions/execute_one_at_a_time.R")
###############################################
# Load data with calculated returns
###############################################
data2 <- load_and_pre_process("data/data1_2024_Q2.RData")
###############################################
# Filtration parameters calculations for each day and moved to next day
###############################################
# Calculating daily linear model regression coefficient,p values
# correlation etc as regP.b, regP.p, regR.b, corP, corR,
# KPSS unit root test (KPSS)
daily.calc <- define_daily_filters(data2)
# remove the last row as it crossess the last quarter last day
daily.calc <- daily.calc[-nrow(daily.calc)]
###############################################
# Entry/Exit parameters calculations
###############################################
#fid av.ratio, sds.ratio and respective spread for both prices and returns
data2 <- define_entry_exit(data2)
data2 <- data2[-nrow(data2)]
###############################################
# Pair trading best parameters estimations
###############################################
# Find the weekly best (based on max SR values) parameters for
# a) volat.sd, b) m_, c) spread_name = 1 (spread_avratio) or 2 (spread_sdsratio)
# d) strategy_name = mr (default)
# these will be need for next week trading decisions
# FUN=execute_strategies iterate on weekly data to perform the task
weeks_points <- endpoints(data2, "weeks")
max_sr <- period.apply(data2, INDEX = weeks_points, FUN = execute_strategies)
# q1 = 1, q2=14, q3=26, q4=40
# find week number for running quarter
# as we need to exclude first week for every quarterly run
# because we are not trading first week of every quarter
first_week_of_quarter <- week(index(data))[1]
first_week_of_quarter
message("First week of running quarter is ", first_week_of_quarter, " one of (1,14,26,40)")
weekly_daily_index <- index(data2[week(index(data2))!=first_week_of_quarter])
# set time from 16:00:00 to 9:30:00 by next two days
index(max_sr) <- index(max_sr) + (2 * 24 * 60 * 60 + .75*24*60*60 - 60*30)
View(max_sr)
# remove the last row as data moved by week ana created out of quarter row
max_sr <- max_sr[-nrow(max_sr)]
# form daily minute frequency result
daily_best_sr <- merge(max_sr,weekly_daily_index)
# Filled the missing with last non-missing values
daily_best_sr$spread.name <- na.locf(daily_best_sr$spread.name)
daily_best_sr$m <- na.locf(daily_best_sr$m)
daily_best_sr$volat.sd <- na.locf(daily_best_sr$volat.sd)
daily_best_sr$net.SR <- na.locf(daily_best_sr$net.SR)
# Add the daily best SR based parameters to main data
data2 <- merge(data2, daily_best_sr)
###############################################
# Execution of trading
###############################################
# FUN=execute_one_at_a_time calculate the daily values
# for various ask, like gross pnl, net pnl, ntrans etc
day_points <- endpoints(data2, "days")
daily.pnls.xts <- period.apply(data2, INDEX = day_points,
FUN = execute_one_at_a_time)
# we need to remove hours from this index
index(daily.pnls.xts) <- as_date(index(daily.pnls.xts))
index(daily.calc) <- as_date(index(daily.calc))
# then we can apply merging
daily.pnls.xts <- merge(daily.pnls.xts, daily.calc)
av.daily.ntrans <- mean(daily.pnls.xts$ntrans, na.rm = TRUE)
ann_gross_sr <- mySR(daily.pnls.xts$pnl.gross[-5],
scale = 252)
ann_net_sr <- mySR(daily.pnls.xts$pnl.net[-5],
scale = 252)
myCalmarRatio <- function(x, # x = series of returns
# scale parameter = Nt
scale) {
scale * mean(coredata(x), na.rm = TRUE) /
maxdrawdown(cumsum(x))$maxdrawdown
}
# sample column
ann_gross_cr <- myCalmarRatio(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)],
scale = 252)
ann_net_cr <-myCalmarRatio(daily.pnls.xts$pnl.net[!is.na(daily.pnls.xts$pnl.net)],
scale = 252)
gross_cumPnL <- tail(cumsum(daily.pnls.xts$pnl.gross[!is.na(daily.pnls.xts$pnl.gross)]),1)
net_cumPnL <- tail(cumsum(daily.pnls.xts$pnl.net[!is.na(daily.pnls.xts$pnl.net)]),1)
net_cumPnL
class(net_cumPnL)
as.numeric(net_cumPnL)
av.daily.ntrans
final_results <- data.frame()
final_results <- rbind(final_results,
data.frame("Gross SR" = ann_gross_sr, "Net SR" = ann_net_sr,
"Gross CR" = ann_gross_cr, "Net CR" = ann_net_cr,
"Gross cumP&L" = as.numeric(gross_cumPnL),
"Net cumP&L" = as.numeric(net_cumPnL),
"Av.ntrades" = av.daily.ntrans))
View(final_results)
abs(net_cumPnL/1000)
abs(as.numeric(net_cumPnL)/1000)
log(abs(as.numeric(net_cumPnL)/1000))
max(0, log(abs(as.numeric(net_cumPnL)/1000)))
ann_net_cr * max(0, log(abs(as.numeric(net_cumPnL)/1000)))
state <- ann_net_cr * max(0, log(abs(as.numeric(net_cumPnL)/1000)))
class(state)
final_results <- data.frame()
#𝑠𝑡𝑎𝑡=𝑛𝑒𝑡𝐶𝑅∗𝑚𝑎𝑥(0,𝑙𝑜𝑔(𝑎𝑏𝑠(𝑛𝑒𝑡.𝑃𝑛𝐿/1000)))
stat_ <- ann_net_cr * max(0, log(abs(as.numeric(net_cumPnL)/1000)))
final_results <- rbind(final_results,
data.frame("Quarter Name" = quarter_name, "Gross SR" = ann_gross_sr, "Net SR" = ann_net_sr,
"Gross CR" = ann_gross_cr, "Net CR" = ann_net_cr,
"Gross cumP&L" = as.numeric(gross_cumPnL),
"Net cumP&L" = as.numeric(net_cumPnL),
"Av.ntrades" = av.daily.ntrans,
"Stat" = stat_))
quarter_name <- "2024_Q2"
final_results <- rbind(final_results,
data.frame("Quarter Name" = quarter_name, "Gross SR" = ann_gross_sr, "Net SR" = ann_net_sr,
"Gross CR" = ann_gross_cr, "Net CR" = ann_net_cr,
"Gross cumP&L" = as.numeric(gross_cumPnL),
"Net cumP&L" = as.numeric(net_cumPnL),
"Av.ntrades" = av.daily.ntrans,
"Stat" = stat_))
View(final_results)
?paste0
source("/Volumes/Macintosh HD 2/Users/vikrambaha/QF-YEAR-2/HFT/project/main_group1.R", echo=TRUE)
source("/Volumes/Macintosh HD 2/Users/vikrambaha/QF-YEAR-2/HFT/project/main_group1.R", echo=TRUE)
View(final_results)
View(gross1_filtered)
View(final_results)
source("/Volumes/Macintosh HD 2/Users/vikrambaha/QF-YEAR-2/HFT/project/main_group1.R", echo=TRUE)
View(final_results)
knitr::opts_chunk$set(echo    = TRUE,
cache   = FALSE, #https://yihui.org/knitr/options/#cache
message = FALSE,
warning = FALSE)
options(scipen = 10)
library(knitr)
# Read the CSV file
data <- read.csv("final_results.csv")
# Read the CSV file
data <- read.csv("final_results.csv")
View(final_results)
View(data)
View(final_results)
View(myTheme)
View(net1_filtered)
